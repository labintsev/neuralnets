# Вопросы по теоретической части на экзамен

1. Краткая история нейросетей. 
2. Основные задачи, решаемые с помощью нейросетей.
3. Жизненный цикл DL проекта. 
4. Основные роли исполнителей проекта. 
5. Линейный классификатор. Постановка задачи и проблемы. 
6. Линейный классификатор. Математическая модель предсказания. 
7. Преобразование Softmax.
8. Функция потерь Cross Entropy.
9. Градиент функции потерь. Частная производная по параметру W.
10. Вычисление градиента численным методом.
11. Вычисление градиента аналитическим методом. 
12. Градиентный спуск. Минибатчи.
13. Два способа выборки батча. 
14. Регуляризация параметра W.
15. Вычислительный граф линейного классификатора с регуляризацией. 
16. Механизм обратного распространения ошибки. 
17. Функция активации sigmoid и tanh.
18. Функция активации ReLU и ее модификации.
19. Начальные значения весов W. Способы инициализации. 
20. Процесс обучения. Графики loss и accuracy в зависимости от эпохи обучения. 
21. Методы поиска оптимальных гиперпараметров. 
22. Переобучение. Его причины и последствия. 
23. Предварительная обработка данных. Нормализация. 
24. Batch Normalization.
25. Регуляризация Dropout. 
26. Регуляризация Augmentation.
27. Проблемы стохастического градиентного спуска. 
28. Оптимизация Momentum. 
29. Оптимизация RMS. 
30. Оптимизация Adam.
31. Снижение скорости обучения (Learning rate decay).
32. Операция свертки двух векторов. Определение, формула, смысл. 
33. Операция 2D свертки. Схема, назначение операции. 
34. Операция 2D свертки над 3D тензором. Схема, особенность третьего измерения. 
35. Сверточный слой нейросети. Карты активации, паддинг, страйд. 
36. Сверточный слой Depthwise. 
37. Сверточный слой Transpose (Upsample). 
38. Сжимающий слой Pooling. Основные параметры, разновидности.  
39. Архитектура AlexNet, основные особенности. 
40. Архитектура VGG, основные особенности.
41. Архитектура GoogleNet, основные особенности.
42. Архитектура ResNet, основные особенности.
43. Семантическая сегментация. Общая схема, особенности архитектуры. 
44. Классификация с локализацией. 
45. Детекция объектов. 
46. Обработка последовательностей. Схемы one-to-one, one-to-many и тд.
47. Рекуррентная модель. Схема, формула, алгоритм работы. 
48. Обучение рекуррентной модели. 
49. Схема языковой модели с рекуррентной сетью. 
50. Описание изображений с помощью CNN и RNN. 
51. Проблема RNN и архитектура LSTM. 
52. Методы векторизации текстов. 
53. Эмбеддинги Word2Vec. 
54. Бинарная классификация текстов с помощью линейной модели. 
55. Обработка текста с помощью RNN. Проблема bottleneck. 
56. Механизм attention. 
57. Архитектура трансформера GPT-1. 
